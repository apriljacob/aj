---
title: 'Assignment #1'
author: "April Jacob"
date: "`r Sys.Date()`"
output:
  pdf_document: default
  html_document: default
  word_document: default
editor_options: 
  markdown: 
    wrap: 72
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(ISLR)
```

Questions No. 2, 5, 6, 8, 9, 10

### 2. Explain whether each scenario is a classification or regression problem,

and indicate whether we are most interested in inference or prediction.
Finally, provide n and p.

a.  We collect a set of data on the top 500 firms in the US. For each
    firm we record profit, number of employees, industry and the CEO
    salary. We are interested in understanding which factors affect CEO
    salary.

```{r}
#regression, inference, n = 500, p = 3
```

b.  We are considering launching a new product and wish to know whether
    it will be a success or a failure. We collect data on 20 similar
    products that were previously launched. For each product we have
    recorded whether it was a success or failure, price charged for the
    product, marketing budget, competition price, and ten other
    variables.

```{r}
#classification, prediction, n = 20, p = 13
```

c.  We are interested in predicting the % change in the USD/Euro
    exchange rate in relation to the weekly changes in the world stock
    markets. Hence we collect weekly data for all of 2012. For each week
    we record the % change in the USD/Euro, the % change in the US
    market, the % change in the British market, and the % change in the
    German market.

```{r}
#regression, prediction, n = 52, p = 3
```

### 5. What are the advantages and disadvantages of a very flexible (versus a less flexible) approach for regression or classification? Under what circumstances might a more flexible approach be preferred to a less flexible approach? When might a less flexible approach be preferred?

```{r Q5}
#The advantages of a flexible approach are less bias.
#The disadvantages of a flexible approach are higher variance and more difficulty interpreting.
#A more flexible approach would be preferred when there are non-linear characteristics.
#A less flexible approach would be preferred when we are interested in inference which makes it more interpretable.
```

### 6. Describe the differences between a parametric and a non-parametric statistical learning approach. What are the advantages of a parametric approach to regression or classification (as opposed to a nonparametric approach)? What are its disadvantages?

```{r Q6}
#Differences: Parametric approach is model-based and assumes f whereas the
#non-parametric approach does not make explicit assumptions but seeks estimates
#of f that gets close without being too rough. 
#Advantages: f is simplified as you only need to estimate the 'p+1' coefficient.
#Disadvantages: the model chosen will not match the true unknown form of f;
#estimate can be very poor
```

### 8. This exercise relates to the College data set, which can be found in the file College.csv on the book website. It contains a number of variables for 777 different universities and colleges in the US. The variables are

Private : Public/private indicator\
Apps : Number of applications received\
Accept : Number of applicants accepted\
Enroll : Number of new students enrolled\
Top10perc : New students from top 10 % of high school class\
Top25perc : New students from top 25 % of high school class\
F.Undergrad : Number of full-time undergraduates\
P.Undergrad : Number of part-time undergraduates\
Outstate : Out-of-state tuition\
Room.Board : Room and board costs\
Books : Estimated book costs\
Personal : Estimated personal spending\
PhD : Percent of faculty with Ph.D.'s\
Terminal : Percent of faculty with terminal degree\
S.F.Ratio : Student/faculty ratio\
perc.alumni : Percent of alumni who donate\
Expend : Instructional expenditure per student\
Grad.Rate : Graduation rate

Before reading the data into R, it can be viewed in Excel or a text
editor.

a.  Use the read.csv() function to read the data into R. Call the loaded
    data college. Make sure that you have the directory set to the
    correct location for the data.

```{r Q8A-setup}
setwd("C:/School/4373 Data Mining/All Data Files")
view(College)
college <- read.csv("College.csv")
```

b.  Look at the data using the View() function. You should notice that
    the first column is just the name of each university. We don't
    really want R to treat this as data. However, it may be handy to
    have these names for later. Try the following commands:
    \>rownames(college)=college[,1] \> View(college)

```{r Q8B1-view}
rownames(college) <- college[, 1]
```

You should see that there is now a row.names column with the name of
each university recorded. This means that R has given each row a name
corresponding to the appropriate university. R will not try to perform
calculations on the row names. However, we still need to eliminate the
first column in the data where the names are stored. Try: \> college \<-
college[, -1] \> View(college)

```{r Q8B2-column-removal}
college <- college[, -1]
head(college)
```

Now you should see that the first data column is Private. Note that
another column labeled row.names now appears before the Private column.
However, this is not a data column but rather the name that R is giving
to each row.

c.  

I.  Use the summary() function to produce a numerical summary of the
    variables in the data set.

```{r Q8Ci-summary}
summary(college)
```

ii. Use the pairs() function to produce a scatterplot matrix of the
    first ten columns or variables of the data. Recall that you can
    reference the first ten columns of a matrix A using A[,1:10].

```{r Q8Cii-scatterplot}
college$Private <- as.factor(college$Private) #had to change Private to a factor variable
pairs(college[, 1:10])
```

iii. Use the plot() function to produce side-by-side boxplots of
     Outstate versus Private.

```{r Q8Ciii-boxplots}
#this was not coming out properly so I switched the x, y
plot(college$Outstate, college$Private,
     xlab = "Tuition Cost",
     ylab = "Private U")

plot(college$Private, college$Outstate,
     xlab = "Private University",
     ylab = "Tuition Cost")
```

iv. Create a new qualitative variable, called elite, by binning the
    Top10perc variable. We are going to divide universities into two
    groups based on whether or not the proportion of students coming
    from the top 10% of their high school classes exceeds 50%. Use the
    summary() function to see how many elite universities there are. Now
    use the plot() function to produce side-by-side boxplots of outstate
    versus elite.

```{r Q8Civ-qualitative-variable}
Elite <- rep("No", nrow(college))
Elite[college$Top10perc > 50] <- "Yes"
Elite <- as.factor(Elite)
college <- data.frame(college, Elite)

plot(college$Elite, college$Outstate,
     xlab = "Elite University",
     ylab = "Tuition in $")
```

v.  Use the hist() function to produce some histograms with differing
    numbers of bins for a few of the qualitative variables. You may find
    the command par(mfrow=c(2,2) useful: it will divide the print window
    into four regions so that four plots can be made simultaneously.
    Modifying the arguments to this function will divide the screen in
    other ways.

```{r Q8Cv-mfrow-4graphs-1pic}
par(mfrow=c(2,2))
hist(college$Enroll, col="chocolate2", xlab = "Number of Students Enrolled", main = "")
hist(college$F.Undergrad, col = "blue", xlab = "Number of Full-Time Undergrad Students", main = "") 
hist(college$P.Undergrad, col="orchid3", xlab = "Number of Part-Time Undergrad Students", main = "")
hist(college$Grad.Rate, col = "deeppink3", xlab = "Gradutation Rate", main = "")
par(mfrow=c(1,1))
```

vi. Continue exploring the data, and provide a brief summary of what you
    discover.

San Antonio, TX
<https://www.bestplaces.net/cost_of_living/city/texas/san_antonio>

Valparaiso, IN
<https://www.bestplaces.net/cost_of_living/city/indiana/valparaiso>

```{r Q8Cvi-my-work-UTSAvValpoU}
#My FIL works at Valpo U, so I thought it would be fun to do a comparison. I originally created averages for an overall estimate of both public and private schools before I realized the numbers would be skewed when comparing a private and public school against each other. I also know there is an easier way to do this but I am only going one step at a time to build a foundation for myself to learn.

row.names(college) #find row no. for schools
UTSA <- college[687,] #public
Valpo <- college[708,] #private

#total no. of applicants
UTSA.Apps <- college[687, 2]
Valpo.Apps <- college[708, 2]
college.Appsavg <- mean(college$Apps)
Public.Apps <- mean(college[college$Private == 'No', 'Apps'])
Private.Apps <- mean(college[college$Private == 'Yes', 'Apps'])

#total no. of accepted applicants
UTSA.Accept <- college[687, 3]
Valpo.Accept <- college[708, 3]
college.Acceptavg <- mean(college$Accept)
Public.Accept <- mean(college[college$Private == 'No', 'Accept'])
Private.Accept <- mean(college[college$Private == 'Yes', 'Accept'])

#percentage of rejected applicants
UTSA.perRej <- ((UTSA.Apps - UTSA.Accept)/((UTSA.Apps + UTSA.Accept)/2) * 100)
Valpo.perRej <- ((Valpo.Apps - Valpo.Accept)/((Valpo.Apps + Valpo.Accept)/2) * 100)
college.perRej <- ((college.Appsavg - college.Acceptavg)/((college.Appsavg + college.Acceptavg)/2) * 100)
Public.perRej <- ((Public.Apps - Public.Accept)/((Public.Apps + Public.Accept)/2) * 100)
Private.perRej <- ((Private.Apps - Private.Accept)/((Private.Apps + Private.Accept)/2) * 100)

#percentage of accepted applicants
UTSA.perAccept <- 100 - UTSA.perRej
Valpo.perAccept <- 100 - Valpo.perRej
college.perAccept <- 100 - college.perRej
Public.perAccept <- 100 - Public.perRej
Private.perAccept <- 100 - Private.perRej

#public & private total cost, *2 as this is costs per semester
Public.Expend <- college[college$Private == 'No', 'Expend']*2
Public.ExpendAvg <- mean(Public.Expend)
Public.Outstate <- college[college$Private == 'No', 'Outstate']
Public.Room.Board <- college[college$Private == 'No', 'Room.Board']
Public.Books <- college[college$Private == 'No', 'Books']
Public.Personal <- college[college$Private == 'No', 'Personal']
Public.TotalCost <- (Public.Outstate + Public.Room.Board + Public.Books + Public.Personal)*2
Public.TotalCost
Public.TotalCostAvg <- mean(Public.TotalCost)
Public.TotalCostAvg


Private.Expend <- college[college$Private == 'Yes', 'Expend']*2
Private.ExpendAvg <- mean(Private.Expend)
Private.Outstate <- college[college$Private == 'Yes', 'Outstate']
Private.Room.Board <- college[college$Private == 'Yes', 'Room.Board']
Private.Books <- college[college$Private == 'Yes', 'Books']
Private.Personal <- college[college$Private == 'Yes', 'Personal']
Private.TotalCost <- (Private.Outstate + Private.Room.Board + Private.Books + Private.Personal)*2
Private.TotalCost
Private.TotalCostAvg <- mean(Private.TotalCost)
Private.TotalCostAvg


#UTSA costs per school year, *2 as this is costs per semester
UTSA.Expend <- college[687,17]*2
UTSA.ExpendAvg <- mean(UTSA.Expend)
UTSA.Outstate <- college[687, 9]
UTSA.Room.Board <- college[687, 10]
UTSA.Books <- college[687, 11]
UTSA.Personal <- college[687, 12]
UTSA.TotalCost <- (UTSA.Outstate + UTSA.Room.Board + UTSA.Books + UTSA.Personal)*2
UTSA.TotalCost
UTSA.TotalCostAvg <- mean(UTSA.TotalCost)
UTSA.TotalCostAvg

#Valpo costs per school year, *2 as this is costs per semester
Valpo.Expend <- college[708,17]*2
Valpo.ExpendAvg <- mean(Valpo.Expend)
Valpo.Outstate <- college[708, 9]
Valpo.Room.Board <- college[708, 10]
Valpo.Books <- college[708, 11]
Valpo.Personal <- college[708, 12]
Valpo.TotalCost <- (Valpo.Outstate + Valpo.Room.Board + Valpo.Books + Valpo.Personal)*2
Valpo.TotalCost
Valpo.TotalCostAvg <- mean(Valpo.TotalCost)
Valpo.TotalCostAvg

#overall costs
college.TotalCost <- (college$Outstate + college$Room.Board + college$Books + college$Personal)*2
college.TotalCostAvg <- mean(college.TotalCost)
college.ExpendAvg <- mean(college$Expend)


#data frame for info to make it easy to view
college.data <- data.frame(
  Public = c(Public.Apps, Public.Accept, Public.perRej, Public.perAccept, Public.TotalCostAvg, Public.ExpendAvg),
  UTSA = c(UTSA.Apps, UTSA.Accept, UTSA.perRej, UTSA.perAccept, UTSA.TotalCostAvg, UTSA.ExpendAvg),
  Private = c(Private.Apps, Private.Accept, Private.perRej, Private.perAccept, Private.TotalCostAvg, Private.ExpendAvg),
  Valpo = c(Valpo.Apps, Valpo.Accept, Valpo.perRej, Valpo.perAccept, Valpo.TotalCostAvg, Valpo.ExpendAvg),
  Overall_Average = c(college.Appsavg, college.Acceptavg, college.perRej, college.perAccept, college.TotalCostAvg, college.ExpendAvg))

row.names(college.data) <- c("Applicants", "Accepted Applicants", "Percent Rejected", "Percent Accepted", "Total Average Cost (Tuition, Room, Board, Books, & Personal)", "Total Average Teacher Expenditure")
row.names(college.data)

#UTSA acceptance rate is 7% higher than the average for public schools.
UTSA.perAccept-Public.perAccept
#Valpo acceptance rate is 22.6% higher than the average for private schools
Valpo.perAccept-Private.perAccept
#Public Schools have a 3% higher acceptance rate on average.
Public.perAccept-Private.perAccept


# Conclusions: Some things I found out was the UTSA acceptance rate is 7% higher than the average for public schools; Valpo's acceptance rate is 22.6% higher than the average for private schools. Public Schools have a 3% higher acceptance rate on average.

#According to the websites posted above, the cost of living in Valpo, IN is at a 99.6 percentile, and San Antonio, TX is at an 89.7 percentile as compared to costs of living nationwide with an index of 100. Based on this data, not only is the cost of attending VU more expensive, the cost of living is also more expensive. UTSA is the clear choice.
```

### 9. This exercise involves the auto data set studied in the lab. Make sure that the missing values have been removed from the data.

```{r}
setwd("C:/School/4373 Data Mining/All Data Files")
auto <- read.csv("Auto.csv", header = TRUE, na.strings = "?")
auto <- na.omit(auto)
```

a.  Which of the predictor are quantitative, and which are qualitative?

```{r}
#The 'name' and 'origin' would be considered qualitative; 'origin' numbers are a reflection of different countries (per information found).

str(auto)
auto$country <- factor(auto$origin, labels = c("American", "European", "Japanese")) #converting the origin numbers to the countries
with(auto, table(country, origin))
qual <- which(names(auto) %in% c("name", "origin", "country")) #qualitative data
qual
```

b.  What is the range of each quantitative predictor? You can answer
    this using the range() function.

```{r}
sapply(auto[, -qual], range)
```

c.  What is the mean and standard deviation of each quantitative
    predictor?

```{r}
sapply(auto[, -qual], mean)
sapply(auto[, -qual], sd)
```

d.  Now remove the 10th through 85th observations. What is the range,
    mean, and standard deviation of each predictor in the subset of the
    data that remains?

```{r}
sapply(auto[-c(10:85), -qual], mean)
sapply(auto[-c(10:85), -qual], sd)
```

e.  Using the full data set, investigate the predictors graphically,
    using scatterplots or other tools of your choice. Create some plots
    highlighting the relationships among the predictors. Comment on your
    findings.

```{r}
attach(auto)
pairs(auto[, -qual])
with(auto, plot(country, mpg), ylab = "mpg")
par(mfrow=c(2,2))
plot(horsepower, mpg, xlab = "Horsepower", ylab = "MPG", main = "Higher HP, Lower MPG")
plot(weight, mpg, xlab = "Weight", ylab = "MPG", main = "Higher Wt., Lower MPG")
plot(cylinders, mpg, xlab = "Cylinders", ylab = "MPG", main = "Higher Cylinders, Lower MPG")
plot(year, mpg, xlab = "Year", ylab = "MPG", main = "Older Vehicles, Lower MPG")
par(mfrow=c(1,1))
```

f.  Suppose that we wish to predict gas mileage (mpg) on the basis of
    the other variables. Do your plots suggest that any of the other
    variables might be useful in predicting mpg? Justify your answer.

```{r}
#The previous plots show the effect other factors have on MPG such as weight and cylinders to name a couple.
```

### 10. This exercise involves the Boston housing data set.

a.  To begin, load in the Boston data set. The Boston data is part of
    the MASS library in R. Range() \>library(MASS) Now the data set is
    contained in the object Boston. \>Boston Read about the data set:
    \>?Boston

```{r}
library(MASS)
?Boston
```

How many rows are in this data set? How many columns? What do the rows
and columns represent?

```{r}
dim(Boston)
str(Boston)

#There are 506 rows and 14 columns in the data set. The rows represent observations of the U.S. Census Tracts in the Boston Area. The columns presents the measures of the Census Variables.
```

b.  Make some pairwise scatterplots of the predictors (columns) in this
    data set. Describe your findings.

```{r}
attach(Boston)
pairs(Boston)
plot(black, lstat) #the majority of black people seem to be in the lower status of the population
plot(medv, crim) #the higher the median value of homes, the lower the crime rate
plot(medv, rm) #the more expensive the home, the more rooms the homes have
```

c.  Are any of the predictors associated with per capita crime rate? If
    so, explain the relationship.

```{r}
cor(Boston)
plot(medv, crim) #the higher the median value of homes, the lower the crime rate
plot(dis, crim) #the closer you are to an employment center, the higher the crime rate
plot(age, crim)
```

d.  Do any of the suburbs of Boston appear to have particularly high
    crime rates? Tax rates? Pupil-teacher ratios? Comment on the range
    of each predictor.

```{r}
hist(crim, breaks = 35) #few suburbs with high crime rates
summary(crim)
hist(tax, breaks = 35) #there is a high figure around the 700 value on x-axis, but there are a larger cluster from 200-400 cluster
summary(tax)
hist(ptratio, breaks = 35) #there is a large spike around the 20 p:t ratio
summary(ptratio)

```

e.  How many of the suburbs in this data set bound the Charles River?

```{r}
nrow(subset(Boston, chas == 1)) #there are 35 suburbs that bound the Charles River.
```

f.  What is the median pupil-teacher ratio among the towns in this data
    set?

```{r}
summary(ptratio)#the median p:t ratio is 19.05.
```

g.  Which suburb of Boston has lowest median value of owner-occupied
    homes? What are the values of the other predictors for that suburb,
    and how do those values compare to the overall ranges for those
    predictors? Comment on your findings.

```{r}
suburb <- Boston[order(medv),]
suburb #suburb #399 has the lowest median value of owner-occupied homes; the median value is $5,000

summary(Boston)
Boston[medv == min(medv),]
#crim, indus, nox, age, rad, tax, ptratio, black, lstat are above the average of Boston suburbs; chas is in line; all others are below the average of Boston suburbs
```

h.  In this data set, how many of the census tracts average more than
    seven rooms per dwelling? More than eight rooms per dwelling?
    Comment on the census tracts that average more than eight rooms per
    dwelling.

```{r}
nrow(subset(Boston, rm > 7))
nrow(subset(Boston, rm > 8))

dwelling <- subset(Boston, rm > 8)
summary(dwelling)
```
